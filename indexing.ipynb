{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import pandas as pd\n",
    "import string\n",
    "import pyterrier as pt\n",
    "from tqdm.auto import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IDX = \"indexes\"\n",
    "\n",
    "# load queries (strip punctuation) and qrels\n",
    "qs = pd.read_csv(\"data/train_queries.csv\", sep=\"\\t\", names=[\"qid\", \"query\"], header=0)\n",
    "qs['query'] = qs['query'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "qrels = pd.read_csv(\"data/train_qrels.csv\", sep=\"\\t\")\n",
    "docs = pd.read_json(\"data/docs.jsonl\", lines=True)\n",
    "\n",
    "qs['qid'] = qs['qid'].astype(str)\n",
    "qrels['qid'] = qrels['qid'].astype(str)\n",
    "\n",
    "# Make text column that is concattenation of title and body\n",
    "docs[\"text\"] = docs[\"title\"] + \" \" + docs[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christianjensen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "docs['body_word_count'] = docs['body'].apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831c9718a0194c47a4620cf6e5d5c14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total Builds:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:06.014 [ForkJoinPool-2-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D3037951) - further warnings are suppressed\n",
      "21:56:33.015 [ForkJoinPool-2-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 302 empty documents\n",
      "21:57:04.164 [ForkJoinPool-3-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D3037951) - further warnings are suppressed\n",
      "21:59:23.251 [ForkJoinPool-3-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 303 empty documents\n",
      "22:00:00.323 [ForkJoinPool-4-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D3037951) - further warnings are suppressed\n",
      "22:02:49.907 [ForkJoinPool-4-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 302 empty documents\n",
      "22:03:25.525 [ForkJoinPool-5-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D3037951) - further warnings are suppressed\n",
      "22:05:59.350 [ForkJoinPool-5-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 303 empty documents\n",
      "22:07:52.389 [ForkJoinPool-6-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D2488975) - further warnings are suppressed\n",
      "22:08:49.895 [ForkJoinPool-6-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n",
      "22:10:59.826 [ForkJoinPool-7-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D2488975) - further warnings are suppressed\n",
      "22:12:22.479 [ForkJoinPool-7-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n",
      "22:14:47.286 [ForkJoinPool-8-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D2488975) - further warnings are suppressed\n",
      "22:15:47.420 [ForkJoinPool-8-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n",
      "22:18:48.435 [ForkJoinPool-9-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D2488975) - further warnings are suppressed\n",
      "22:19:44.668 [ForkJoinPool-9-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n",
      "Build times summary (s):\n",
      "                                      mean  std         min         max\n",
      "full_index                      180.746061  NaN  180.746061  180.746061\n",
      "stopwords_removed               169.346000  NaN  169.346000  169.346000\n",
      "stemming_only                   207.873301  NaN  207.873301  207.873301\n",
      "stopwords_and_stemming          188.702945  NaN  188.702945  188.702945\n",
      "full_index_trimmed              169.555236  NaN  169.555236  169.555236\n",
      "stopwords_removed_trimmed       215.245701  NaN  215.245701  215.245701\n",
      "stemming_only_trimmed           203.982469  NaN  203.982469  203.982469\n",
      "stopwords_and_stemming_trimmed  237.140186  NaN  237.140186  237.140186\n"
     ]
    }
   ],
   "source": [
    "NO_STEM = pt.TerrierStemmer.none\n",
    "\n",
    "configs = {\n",
    "    \"full_index\": {\n",
    "        \"stopwords\": None,\n",
    "        \"stemmer\"  : NO_STEM,\n",
    "    },\n",
    "    \"stopwords_removed\": {\n",
    "        \"stemmer\": NO_STEM,\n",
    "    },\n",
    "    \"stemming_only\": {\n",
    "        \"stopwords\": None,\n",
    "    },\n",
    "    \"stopwords_and_stemming\": {\n",
    "        # defaults\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "N_BUILDS = 1\n",
    "build_times = {name: [] for name in configs}\n",
    "build_times.update({name + \"_trimmed\": [] for name in configs})\n",
    "\n",
    "lower = docs['body_word_count'].quantile(0.01)\n",
    "upper = docs['body_word_count'].quantile(0.99)\n",
    "\n",
    "total_runs = N_BUILDS * 2 * len(configs)\n",
    "\n",
    "with tqdm(total=total_runs, desc=\"Total Builds\") as pbar:\n",
    "    for run in range(N_BUILDS):\n",
    "        for trimmed in (False, True):\n",
    "            for name, opts in configs.items():\n",
    "                run_name = f\"{name}_trimmed\" if trimmed else f\"{name}\"\n",
    "                abs_idx = os.path.abspath(os.path.join(BASE_IDX, run_name))\n",
    "                \n",
    "                # wipe & rebuild\n",
    "                if os.path.isdir(abs_idx): shutil.rmtree(abs_idx)\n",
    "                os.makedirs(abs_idx, exist_ok=True)\n",
    "\n",
    "                # idxer = pt.IterDictIndexer(abs_idx, text_attrs=[\"title\", \"body\"], fields=False, **opts)\n",
    "                idxer = pt.IterDictIndexer(abs_idx, text_attrs=(\"text\",), fields=False, **opts)\n",
    "                if trimmed:\n",
    "                    to_index = docs[\n",
    "                            (docs['body_word_count'] > lower) &\n",
    "                            (docs['body_word_count'] < upper)\n",
    "                        ].to_dict(orient='records')\n",
    "                else:\n",
    "                    to_index = docs.to_dict(orient='records')\n",
    "                t0 = time.perf_counter()\n",
    "                idx_ref = idxer.index()\n",
    "                build_times[run_name].append(time.perf_counter() - t0)\n",
    "                pbar.update(1)\n",
    "# quick summary\n",
    "bt = pd.DataFrame(build_times)\n",
    "print(\"Build times summary (s):\")\n",
    "print(bt.describe().T[[\"mean\",\"std\",\"min\",\"max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build times summary (s):\n",
      "                                      mean        std         min         max\n",
      "full_index                      224.361024  17.764385  210.837642  255.471691\n",
      "full_index_trimmed              200.103897  12.415554  187.870443  219.609771\n",
      "stopwords_removed               206.471247  14.796586  194.001272  231.351704\n",
      "stopwords_removed_trimmed       188.053850  11.411245  175.334452  198.935515\n",
      "stemming_only                   219.873281   8.411347  209.852369  232.689631\n",
      "stemming_only_trimmed           210.452104  20.494514  192.553874  240.537750\n",
      "stopwords_and_stemming          197.518740  10.622081  187.514076  215.243656\n",
      "stopwords_and_stemming_trimmed  187.346538  20.582123  168.839451  217.388120\n"
     ]
    }
   ],
   "source": [
    "bt = pd.DataFrame(build_times)\n",
    "print(\"Build times summary (s):\")\n",
    "print(bt.describe().T[[\"mean\",\"std\",\"min\",\"max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Docs Indexed</th>\n",
       "      <th>Unique Terms</th>\n",
       "      <th>Total Terms</th>\n",
       "      <th>Avg Doc Length</th>\n",
       "      <th>Size (MB)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stemming_only</th>\n",
       "      <td>200000</td>\n",
       "      <td>2654799</td>\n",
       "      <td>375471589</td>\n",
       "      <td>1877.357945</td>\n",
       "      <td>515.809729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_removed_trimmed</th>\n",
       "      <td>195953</td>\n",
       "      <td>2629000</td>\n",
       "      <td>194362712</td>\n",
       "      <td>991.884340</td>\n",
       "      <td>481.956937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_and_stemming_trimmed</th>\n",
       "      <td>195953</td>\n",
       "      <td>2403925</td>\n",
       "      <td>194362712</td>\n",
       "      <td>991.884340</td>\n",
       "      <td>426.835865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stemming_only_trimmed</th>\n",
       "      <td>195953</td>\n",
       "      <td>2404075</td>\n",
       "      <td>326621929</td>\n",
       "      <td>1666.838114</td>\n",
       "      <td>471.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_and_stemming</th>\n",
       "      <td>200000</td>\n",
       "      <td>2654647</td>\n",
       "      <td>222689568</td>\n",
       "      <td>1113.447840</td>\n",
       "      <td>465.550773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_removed</th>\n",
       "      <td>200000</td>\n",
       "      <td>2912126</td>\n",
       "      <td>222689568</td>\n",
       "      <td>1113.447840</td>\n",
       "      <td>526.370728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_index</th>\n",
       "      <td>200000</td>\n",
       "      <td>2912731</td>\n",
       "      <td>375471589</td>\n",
       "      <td>1877.357945</td>\n",
       "      <td>579.105363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_index_trimmed</th>\n",
       "      <td>195953</td>\n",
       "      <td>2629597</td>\n",
       "      <td>326621929</td>\n",
       "      <td>1666.838114</td>\n",
       "      <td>529.467052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Docs Indexed  Unique Terms  Total Terms  \\\n",
       "Index                                                                     \n",
       "stemming_only                         200000       2654799    375471589   \n",
       "stopwords_removed_trimmed             195953       2629000    194362712   \n",
       "stopwords_and_stemming_trimmed        195953       2403925    194362712   \n",
       "stemming_only_trimmed                 195953       2404075    326621929   \n",
       "stopwords_and_stemming                200000       2654647    222689568   \n",
       "stopwords_removed                     200000       2912126    222689568   \n",
       "full_index                            200000       2912731    375471589   \n",
       "full_index_trimmed                    195953       2629597    326621929   \n",
       "\n",
       "                                Avg Doc Length   Size (MB)  \n",
       "Index                                                       \n",
       "stemming_only                      1877.357945  515.809729  \n",
       "stopwords_removed_trimmed           991.884340  481.956937  \n",
       "stopwords_and_stemming_trimmed      991.884340  426.835865  \n",
       "stemming_only_trimmed              1666.838114  471.947236  \n",
       "stopwords_and_stemming             1113.447840  465.550773  \n",
       "stopwords_removed                  1113.447840  526.370728  \n",
       "full_index                         1877.357945  579.105363  \n",
       "full_index_trimmed                 1666.838114  529.467052  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_folders = [d for d in os.listdir(BASE_IDX) if os.path.isdir(os.path.join(BASE_IDX, d))]\n",
    "\n",
    "records = []\n",
    "for name in index_folders:\n",
    "    abs_idx = os.path.abspath(os.path.join(BASE_IDX, name))\n",
    "    if not os.path.isdir(abs_idx):\n",
    "        # Skip if directory does not exist\n",
    "        continue\n",
    "    # Load the index\n",
    "    idx = pt.IndexFactory.of(abs_idx)\n",
    "    stats = idx.getCollectionStatistics()\n",
    "    \n",
    "    docs_indexed = stats.getNumberOfDocuments()\n",
    "    unique_terms = stats.getNumberOfUniqueTerms()\n",
    "    total_terms = stats.getNumberOfTokens()\n",
    "    avg_doc_length = stats.getAverageDocumentLength()\n",
    "\n",
    "    # Calculate size on disk (MB)\n",
    "    size_bytes = 0\n",
    "    for root, _, files in os.walk(abs_idx):\n",
    "        for f in files:\n",
    "            size_bytes += os.path.getsize(os.path.join(root, f))\n",
    "    size_mb = size_bytes / (1024 ** 2)\n",
    "    \n",
    "    records.append({\n",
    "        \"Index\": name,\n",
    "        \"Docs Indexed\": docs_indexed,\n",
    "        \"Unique Terms\": unique_terms,\n",
    "        \"Total Terms\": total_terms,\n",
    "        \"Avg Doc Length\": avg_doc_length,\n",
    "        \"Size (MB)\": size_mb\n",
    "    })\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(records).set_index(\"Index\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean relative changes:\n",
      "Docs Indexed %Δ   -0.020235\n",
      "Unique Terms %Δ   -0.095829\n",
      "Total Terms %Δ    -0.128653\n",
      "Size (MB) %Δ      -0.084572\n",
      "Name: Mean %Δ, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "trimmed = df[df.index.str.endswith(\"_trimmed\")].copy()\n",
    "trimmed['base'] = trimmed.index.str.replace(r'_trimmed$', '', regex=True)\n",
    "base     = df.loc[trimmed['base']].copy()\n",
    "base.index = trimmed.index  # align indices\n",
    "\n",
    "# 2. pull just the numeric metric columns\n",
    "metrics = [\"Docs Indexed\", \"Unique Terms\", \"Total Terms\", \"Size (MB)\"]\n",
    "trim_m = trimmed[metrics]\n",
    "base_m  = base[metrics]\n",
    "\n",
    "# 3. absolute difference\n",
    "abs_diff = trim_m - base_m\n",
    "abs_diff.columns = [f\"{c} Δ\" for c in abs_diff.columns]\n",
    "\n",
    "# 4. relative change (proportional)\n",
    "rel_change = abs_diff.values / base_m.values\n",
    "rel = pd.DataFrame(rel_change, index=abs_diff.index, columns=metrics)\n",
    "rel.columns = [f\"{c} %Δ\" for c in rel.columns]\n",
    "\n",
    "# 5. mean relative change across all trimmed runs\n",
    "mean_rel = rel.mean().rename(\"Mean %Δ\")\n",
    "\n",
    "# 6. combine for display if you like\n",
    "result = pd.concat([trim_m, base_m.add_prefix(\"Base \"), abs_diff, rel], axis=1)\n",
    "\n",
    "print(\"\\nMean relative changes:\")\n",
    "print(mean_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4434/4434 [1:03:06<00:00,  1.17it/s]\n",
      "100%|██████████| 4434/4434 [07:40<00:00,  9.63it/s]\n",
      "100%|██████████| 4434/4434 [08:24<00:00,  8.78it/s]\n",
      "100%|██████████| 4434/4434 [50:01<00:00,  1.48it/s]  \n",
      "100%|██████████| 4434/4434 [07:45<00:00,  9.53it/s]\n",
      "100%|██████████| 4434/4434 [06:08<00:00, 12.04it/s]\n",
      "100%|██████████| 4434/4434 [54:15<00:00,  1.36it/s]  \n",
      "100%|██████████| 4434/4434 [44:38<00:00,  1.66it/s]  \n"
     ]
    }
   ],
   "source": [
    "from avg_query_process_time import process_queries\n",
    "\n",
    "query_times = {}\n",
    "\n",
    "# Get all index folders in BASE_IDX\n",
    "index_folders = [d for d in os.listdir(BASE_IDX) if os.path.isdir(os.path.join(BASE_IDX, d))]\n",
    "\n",
    "for name in index_folders:\n",
    "    idx_ref = os.path.abspath(os.path.join(BASE_IDX, name))\n",
    "    processing_time, postings_time = process_queries(qs, idx_ref)\n",
    "    query_times[name] = postings_time\n",
    "\n",
    "query_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building block index in /Users/christianjensen/Documents/search-engines/debug_indexes/full_index_with_blocks...\n",
      "09:49:57.884 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (D3037951) - further warnings are suppressed\n",
      "09:56:39.860 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer -- Indexed 302 empty documents\n",
      "Done in 486.65 seconds.\n"
     ]
    }
   ],
   "source": [
    "DEBUG_IDX = os.path.abspath(os.path.join(\"debug_indexes\", \"full_index_with_blocks\"))\n",
    "if os.path.isdir(DEBUG_IDX):\n",
    "    shutil.rmtree(DEBUG_IDX)\n",
    "os.makedirs(DEBUG_IDX, exist_ok=True)\n",
    "\n",
    "block_indexer = pt.IterDictIndexer(DEBUG_IDX, blocks=True, stopwords=None, stemmer=NO_STEM)\n",
    "to_index = docs.to_dict(orient='records')\n",
    "print(f\"Building block index in {DEBUG_IDX}...\")\n",
    "t0 = time.perf_counter()\n",
    "block_indexer.index(to_index)\n",
    "print(f\"Done in {time.perf_counter() - t0:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
